# A list of MSA papers
|Year|Title|Network|Publish|Paper|Code|
|:-:|:-:|:-:|:-:|:-:|:-:|
|2019|Multimodal Transformer for Unaligned Multimodal Language Sequences|MulT|ACL|[link](https://arxiv.org/abs/1906.00295)|[code](https://github.com/yaohungt/Multimodal-Transformer)|
|2020|CM-BERT: Cross-Modal BERT for Text-Audio Sentiment Analysis|CM-BERT|ACM MM|[link](https://dl.acm.org/doi/10.1145/3394171.3413690)|[code](https://github.com/thuiar/Cross-Modal-BERT)|
|2020|Integrating Multimodal Information in Large Pretrained Transformers|MAG|ACL|[link](https://arxiv.org/abs/1908.05787)|[code](https://github.com/WasifurRahman/BERT_multimodal_transformer)|
|2020|MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis|MISA|ACM MM|[link](https://doi.org/10.1145/3394171.3413678)|[code](https://github.com/declare-lab/MISA)|
|2021|Bi-Bimodal Modality Fusion for Correlation-Controlled Multimodal Sentiment Analysis|BBFN|ICMI|[link](https://doi.org/10.1145/1122445.1122456)|[code](https://github.com/declare-lab/multimodal-deep-learning)|
|2021|CTNet: Conversational Transformer Network for Emotion Recognition|CTNet|IEEE-ACM T AUDIO SPE|[link](https://ieeexplore.ieee.org/document/9316758)|-|
|2021|Hybrid Contrastive Learning of Tri-Modal Representation for Multimodal Sentiment Analysis|HyCon|Under Review|[link](https://arxiv.org/abs/2109.01797)|-|
|2021|Improving Multimodal Fusion with Hierarchical Mutual Information Maximization for Multimodal Sentiment Analysis|MMIM|EMNLP|[link](https://arxiv.org/pdf/2109.00412.pdf)|[code](https://github.com/declare-lab/Multimodal-Infomax)|
|2021|Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis|Self-MM|AAAI|[link](https://arxiv.org/abs/2102.04830)|[code](https://github.com/thuiar/Self-MM)|
|2021|MSAF: Multimodal Split Attention Fusion|MSAF|Under Review|[link](https://arxiv.org/abs/2012.07175)|-|
|2022|AMOA: Global Acoustic Feature Enhanced Modal-Order-Aware Network for Multimodal Sentiment Analysis|AMOA|COLING|[link](https://aclanthology.org/2022.coling-1.623/)|-|
|2022|BAFN: Bi-direction Attention based Fusion Network for Multimodal Sentiment Analysis|BAFN|TCSVT|[link](https://ieeexplore.ieee.org/document/9932611)|-|
|2022|CLMLF:A Contrastive Learning and Multi-Layer Fusion Method for Multimodal Sentiment Detection|CLMLF|NAACL|[link](https://arxiv.org/abs/2204.05515)|[code](https://github.com/Link-Li/CLMLF)|
|2022|Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis|CLUE|ACM MM|[link](https://dl.acm.org/doi/10.1145/3503161.3548211)|[code](https://github.com/Teng-Sun/CLUE_model)|
|2022|CubeMLP: An MLP-based Model for Multimodal Sentiment Analysis and Depression Estimation|CubeMLP|ACM MM|[link](https://doi.org/10.1145/3503161.3548025)|-|
|2022|Disentangled Representation Learning for Multimodal Emotion Recognition|FDMER|ACM MM|[link](https://doi.org/10.1145/3503161.3547754)|-|
|2022|Dynamically Adjust Word Representations Using Unaligned Multimodal Information|CHFN|ACM MM|[link](https://doi.org/10.1145/3503161.3548137)|-|
|2022|EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition|EmoCaps|ACL|[link](https://arxiv.org/abs/2203.13504)|-|
|2022|FEW-SHOT MULTIMODAL SENTIMENT ANALYSIS BASED ON MULTIMODAL PROBABILISTIC FUSION PROMPTS|MultiPoint|Under Review|[link](https://arxiv.org/abs/2211.06607)|[code](https://github.com/YangXiaocui1215/MultiPoint)|
|2022|Leveraging Multi-modal Interactions among the Intermediate Representations of Deep Transformers for Emotion Recognition|RILA|ACM MM|[link](https://doi.org/10.1145/3551876.3554813)|-|
|2022|M-SENA: An Integrated Platform for Multimodal Sentiment Analysis|M-SENA|ACL|[link](https://arxiv.org/abs/2203.12441)|[code](https://github.com/thuiar/M-SENA)|
|2022|Multimodal Contrastive Learning via Uni-Modal Coding and Cross-Modal Prediction for Multimodal Sentiment Analysis|MMCL|EMNLP|[link](https://arxiv.org/abs/2210.14556)|-|
|2022|Multimodal Information Bottleneck: Learning Minimal Sufficient Unimodal and Multimodal Representations|MIB|TMM|[link](https://arxiv.org/abs/2210.17444)|[code](https://github.com/TmacMai/Multimodal-Information-Bottleneck)|
|2022|MULTIMODAL SENTIMENT ANALYSIS ON UNALIGNED SEQUENCES VIA HOLOGRAPHIC EMBEDDING|HEMT|ICASSP|[link](https://ieeexplore.ieee.org/document/9747646)|-|
|2022|Multimodal Temporal Attention in Sentiment Analysis|MMTA|ACM MM|[link](https://dl.acm.org/doi/10.1145/3551876.3554811)|-|
|2022|TVLT: Textless Vision-Language Transformer|TVLT|NeurIPS|[link](https://arxiv.org/abs/2209.14156)|[code](https://github.com/zinengtang/TVLT)|
|2022|Unified Multi-modal Pre-training for Few-shot Sentiment Analysis with Prompt-based Learning|UP-MPF|ACM MM|[link](https://doi.org/10.1145/3503161.3548306)|[code](https://github.com/yynj98/UP-MPF)|
|2022|UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition|UniMSE|EMNLP|[link](https://arxiv.org/pdf/2211.11256.pdf)|[code](https://github.com/LeMei/UniMSE)|
|2023|A Deep Multi-level Attentive Network for Multimodal Sentiment Analysis|DMLANet|ACM MM|[link](https://doi.org/10.1145/3517139)|-|
|2023|PS-Mixer: A Polar-Vector and Strength-Vector Mixer Model for Multimodal Sentiment Analysis|PS-Mixer|IPM|[link](https://doi.org/10.1016/j.ipm.2022.103229)|[link](https://github.com/metaphysicser/PS-Mixer)|
<!-- |2022|CubeMLP: A MLP-based Model for Multimodal Sentiment Analysis and Depression Estimation|CubeMLP|ACM MM|[link](https://arxiv.org/abs/2207.14087)|-|
|2022|Dynamically Adjust Word Representations Using Unaligned Multimodal Information|CHFN|ACM MM|[link](https://dl.acm.org/doi/abs/10.1145/3503161.3548137)|-| -->